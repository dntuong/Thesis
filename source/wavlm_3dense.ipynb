{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZkXqLWNWEKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8101c45c-7071-45eb-e80c-87c755f54c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Original: 1012\n",
        "# current: epoch 48\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install s3prl -q\n",
        "!pip install hydra-core -q\n",
        "!pip install sentencepiece -q\n",
        "!pip uninstall omegaconf -y\n",
        "!pip install omegaconf\n",
        "!pip install fairseq -q"
      ],
      "metadata": {
        "id": "Zz92Nz22SpDM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "outputId": "9ce88b1b-65cf-44df-c915-38e25330fe7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for s3prl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "arviz 0.15.1 requires setuptools>=60.0.0, but you have setuptools 59.5.0 which is incompatible.\n",
            "cvxpy 1.3.1 requires setuptools>65.5.1, but you have setuptools 59.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hFound existing installation: omegaconf 2.3.0\n",
            "Uninstalling omegaconf-2.3.0:\n",
            "  Successfully uninstalled omegaconf-2.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting omegaconf\n",
            "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0)\n",
            "Installing collected packages: omegaconf\n",
            "Successfully installed omegaconf-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/9.6 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m157.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "s3prl 0.4.10 requires omegaconf>=2.1.1, but you have omegaconf 2.0.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "const_path = '/content/gdrive/MyDrive/'"
      ],
      "metadata": {
        "id": "RaESucG0buTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "py_file_location = const_path + '/KLTN/source/wavlm_large'\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "import fairseq\n",
        "import tqdm\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import *\n",
        "import scipy.interpolate, scipy.optimize\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import time\n",
        "from scipy.spatial import distance\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from typing import *\n",
        "import librosa\n",
        "from scipy.ndimage import binary_dilation\n",
        "import struct\n",
        "from torchaudio.transforms import Resample\n",
        "import torchaudio.transforms as trans\n",
        "from s3prl.upstream.interfaces import UpstreamBase\n",
        "from packaging import version\n",
        "from fairseq import tasks\n",
        "from fairseq.checkpoint_utils import load_checkpoint_to_cpu\n",
        "from fairseq.dataclass.utils import convert_namespace_to_omegaconf\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from omegaconf import OmegaConf"
      ],
      "metadata": {
        "id": "yZlOe8iUcd3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/gdrive/MyDrive/KLTN/dataset/zalo_dataset/dataset_fix/train\"\n",
        "train_list = \"/content/gdrive/MyDrive/KLTN/dataset/zalo_dataset/dataset_fix/train_list.txt\"\n",
        "\n",
        "eval_path = \"/content/gdrive/MyDrive/KLTN/dataset/zalo_dataset/dataset_fix/val\"\n",
        "eval_list = \"/content/gdrive/MyDrive/KLTN/dataset/zalo_dataset/dataset_fix/veri_val.txt\"\n",
        "\n",
        "save_path = \"/content/gdrive/MyDrive/KLTN/source/wavlm_large/component\""
      ],
      "metadata": {
        "id": "3dd3TMisAslc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training setting batch30 for wavlm unfreeze, batch150 for ecapatdnn\n",
        "n_cpu = 2\n",
        "num_frames = 300 # 300 for 3 seconds\n",
        "max_epoch = 20\n",
        "batch_size = 150\n",
        "# batch_size = 30\n",
        "lr = 0.001\n",
        "lr_decay = 0.97\n",
        "test_step = 1\n",
        "epoch = 48 # Init epoch\n",
        "\n",
        "# Model setting\n",
        "n_class = 5994 # Default n_speakers\n",
        "C = 1024 # Channel size\n",
        "m = 0.2 # Loss margin\n",
        "s = 32 # Loss scale"
      ],
      "metadata": {
        "id": "u34-n9U9C6QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/TaoRuijie/ECAPA-TDNN\n",
        "import glob, numpy, os, random, soundfile, torch\n",
        "from scipy import signal\n",
        "\n",
        "class train_loader(object):\n",
        "\tdef __init__(self, train_list, train_path, num_frames, musan_path = None, rir_path = None, **kwargs):\n",
        "\t\tself.train_path = train_path\n",
        "\t\tself.num_frames = num_frames\n",
        "\t\t# Load and configure augmentation files\n",
        "\t\t# self.noisetypes = ['noise','speech','music']\n",
        "\t\t# self.noisesnr = {'noise':[0,15],'speech':[13,20],'music':[5,15]}\n",
        "\t\t# self.numnoise = {'noise':[1,1], 'speech':[3,8], 'music':[1,1]}\n",
        "\t\t# self.noiselist = {}\n",
        "\t\t# augment_files   = glob.glob(os.path.join(musan_path,'*/*/*/*.wav'))\n",
        "\t\t# for file in augment_files:\n",
        "\t\t# \tif file.split('/')[-4] not in self.noiselist:\n",
        "\t\t# \t\tself.noiselist[file.split('/')[-4]] = []\n",
        "\t\t# \tself.noiselist[file.split('/')[-4]].append(file)\n",
        "\t\t# self.rir_files  = glob.glob(os.path.join(rir_path,'*/*/*.wav'))\n",
        "\t\t# Load data & labels\n",
        "\t\tself.data_list  = []\n",
        "\t\tself.data_label = []\n",
        "\t\tlines = open(train_list).read().splitlines()\n",
        "\t\tdictkeys = list(set([x.split()[0] for x in lines]))\n",
        "\t\tdictkeys.sort()\n",
        "\t\tdictkeys = { key : ii for ii, key in enumerate(dictkeys) }\n",
        "\t\tfor index, line in enumerate(lines):\n",
        "\t\t\tspeaker_label = dictkeys[line.split()[0]]\n",
        "\t\t\tfile_name     = os.path.join(train_path, line.split()[1])\n",
        "\t\t\tself.data_label.append(speaker_label)\n",
        "\t\t\tself.data_list.append(file_name)\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\t# Read the utterance and randomly select the segment\n",
        "\t\taudio, sr = soundfile.read(self.data_list[index])\n",
        "\t\tlength = self.num_frames * 160 + 240\n",
        "\t\tif audio.shape[0] <= length:\n",
        "\t\t\tshortage = length - audio.shape[0]\n",
        "\t\t\taudio = numpy.pad(audio, (0, shortage), 'wrap')\n",
        "\t\tstart_frame = numpy.int64(random.random()*(audio.shape[0]-length))\n",
        "\t\taudio = audio[start_frame:start_frame + length]\n",
        "\t\taudio = numpy.stack([audio],axis=0)\n",
        "\t\t# Data Augmentation\n",
        "\t\t# augtype = random.randint(0,5)\n",
        "\t\t# if augtype == 0:   # Original\n",
        "\t\t# \taudio = audio\n",
        "\t\t# elif augtype == 1: # Reverberation\n",
        "\t\t# \taudio = self.add_rev(audio)\n",
        "\t\t# elif augtype == 2: # Babble\n",
        "\t\t# \taudio = self.add_noise(audio, 'speech')\n",
        "\t\t# elif augtype == 3: # Music\n",
        "\t\t# \taudio = self.add_noise(audio, 'music')\n",
        "\t\t# elif augtype == 4: # Noise\n",
        "\t\t# \taudio = self.add_noise(audio, 'noise')\n",
        "\t\t# elif augtype == 5: # Television noise\n",
        "\t\t# \taudio = self.add_noise(audio, 'speech')\n",
        "\t\t# \taudio = self.add_noise(audio, 'music')\n",
        "\t\treturn torch.FloatTensor(audio[0]), self.data_label[index]\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data_list)\n",
        "\n",
        "\t# def add_rev(self, audio):\n",
        "\t# \trir_file    = random.choice(self.rir_files)\n",
        "\t# \trir, sr     = soundfile.read(rir_file)\n",
        "\t# \trir         = numpy.expand_dims(rir.astype(numpy.float),0)\n",
        "\t# \trir         = rir / numpy.sqrt(numpy.sum(rir**2))\n",
        "\t# \treturn signal.convolve(audio, rir, mode='full')[:,:self.num_frames * 160 + 240]\n",
        "\n",
        "\t# def add_noise(self, audio, noisecat):\n",
        "\t# \tclean_db    = 10 * numpy.log10(numpy.mean(audio ** 2)+1e-4)\n",
        "\t# \tnumnoise    = self.numnoise[noisecat]\n",
        "\t# \tnoiselist   = random.sample(self.noiselist[noisecat], random.randint(numnoise[0],numnoise[1]))\n",
        "\t# \tnoises = []\n",
        "\t# \tfor noise in noiselist:\n",
        "\t# \t\tnoiseaudio, sr = soundfile.read(noise)\n",
        "\t# \t\tlength = self.num_frames * 160 + 240\n",
        "\t# \t\tif noiseaudio.shape[0] <= length:\n",
        "\t# \t\t\tshortage = length - noiseaudio.shape[0]\n",
        "\t# \t\t\tnoiseaudio = numpy.pad(noiseaudio, (0, shortage), 'wrap')\n",
        "\t# \t\tstart_frame = numpy.int64(random.random()*(noiseaudio.shape[0]-length))\n",
        "\t# \t\tnoiseaudio = noiseaudio[start_frame:start_frame + length]\n",
        "\t# \t\tnoiseaudio = numpy.stack([noiseaudio],axis=0)\n",
        "\t# \t\tnoise_db = 10 * numpy.log10(numpy.mean(noiseaudio ** 2)+1e-4)\n",
        "\t# \t\tnoisesnr   = random.uniform(self.noisesnr[noisecat][0],self.noisesnr[noisecat][1])\n",
        "\t# \t\tnoises.append(numpy.sqrt(10 ** ((clean_db - noise_db - noisesnr) / 10)) * noiseaudio)\n",
        "\t# \tnoise = numpy.sum(numpy.concatenate(noises,axis=0),axis=0,keepdims=True)\n",
        "\t# \treturn noise + audio"
      ],
      "metadata": {
        "id": "DJxby5TT9gyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader  = train_loader(train_list, train_path, num_frames)\n",
        "trainLoader = torch.utils.data.DataLoader(trainloader, batch_size = batch_size, shuffle = True, num_workers = n_cpu, pin_memory=False, drop_last = False)"
      ],
      "metadata": {
        "id": "SZRMN2kNCraH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(filepath):\n",
        "    state = torch.load(filepath, map_location=lambda storage, loc: storage)\n",
        "    # state = load_checkpoint_to_cpu(filepath)\n",
        "    state[\"cfg\"] = OmegaConf.create(state[\"cfg\"])\n",
        "\n",
        "    if \"args\" in state and state[\"args\"] is not None:\n",
        "        cfg = convert_namespace_to_omegaconf(state[\"args\"])\n",
        "    elif \"cfg\" in state and state[\"cfg\"] is not None:\n",
        "        cfg = state[\"cfg\"]\n",
        "    else:\n",
        "        raise RuntimeError(\n",
        "            f\"Neither args nor cfg exist in state keys = {state.keys()}\"\n",
        "            )\n",
        "\n",
        "    task = tasks.setup_task(cfg.task)\n",
        "    if \"task_state\" in state:\n",
        "        task.load_state_dict(state[\"task_state\"])\n",
        "\n",
        "    model = task.build_model(cfg.model)\n",
        "\n",
        "    return model, cfg, task\n",
        "\n",
        "class UpstreamExpert(UpstreamBase):\n",
        "    def __init__(self, ckpt, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        assert version.parse(fairseq.__version__) > version.parse(\n",
        "            \"0.10.2\"\n",
        "        ), \"Please install the fairseq master branch.\"\n",
        "\n",
        "        model, cfg, task = load_model(ckpt)\n",
        "        self.model = model\n",
        "        self.task = task\n",
        "\n",
        "        if len(self.hooks) == 0:\n",
        "            module_name = \"self.model.encoder.layers\"\n",
        "            for module_id in range(len(eval(module_name))):\n",
        "                self.add_hook(\n",
        "                    f\"{module_name}[{module_id}]\",\n",
        "                    lambda input, output: input[0].transpose(0, 1),\n",
        "                )\n",
        "            self.add_hook(\"self.model.encoder\", lambda input, output: output[0])\n",
        "\n",
        "    def forward(self, wavs):\n",
        "        if self.task.cfg.normalize:\n",
        "            wavs = [F.layer_norm(wav, wav.shape) for wav in wavs]\n",
        "\n",
        "        device = wavs[0].device\n",
        "        wav_lengths = torch.LongTensor([len(wav) for wav in wavs]).to(device)\n",
        "        wav_padding_mask = ~torch.lt(\n",
        "            torch.arange(max(wav_lengths)).unsqueeze(0).to(device),\n",
        "            wav_lengths.unsqueeze(1),\n",
        "        )\n",
        "        padded_wav = pad_sequence(wavs, batch_first=True)\n",
        "\n",
        "        features, feat_padding_mask = self.model.extract_features(\n",
        "            padded_wav,\n",
        "            padding_mask=wav_padding_mask,\n",
        "            mask=None,\n",
        "        )\n",
        "        return {\n",
        "            \"default\": features,\n",
        "        }"
      ],
      "metadata": {
        "id": "H_bqPQdSSYts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res"
      ],
      "metadata": {
        "id": "zgjLXlHEFVMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "AAMsoftmax loss function copied from voxceleb_trainer: https://github.com/clovaai/voxceleb_trainer/blob/master/loss/aamsoftmax.py\n",
        "'''\n",
        "\n",
        "import torch, math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AAMsoftmax(nn.Module):\n",
        "    def __init__(self, n_class, m, s):\n",
        "\n",
        "        super(AAMsoftmax, self).__init__()\n",
        "        self.m = m\n",
        "        self.s = s\n",
        "        self.weight = torch.nn.Parameter(torch.FloatTensor(n_class, 256), requires_grad=True)\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        nn.init.xavier_normal_(self.weight, gain=1)\n",
        "        self.cos_m = math.cos(self.m)\n",
        "        self.sin_m = math.sin(self.m)\n",
        "        self.th = math.cos(math.pi - self.m)\n",
        "        self.mm = math.sin(math.pi - self.m) * self.m\n",
        "\n",
        "    def forward(self, x, label=None):\n",
        "\n",
        "        cosine = F.linear(F.normalize(x), F.normalize(self.weight))\n",
        "        sine = torch.sqrt((1.0 - torch.mul(cosine, cosine)).clamp(0, 1))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        phi = torch.where((cosine - self.th) > 0, phi, cosine - self.mm)\n",
        "        one_hot = torch.zeros_like(cosine)\n",
        "        one_hot.scatter_(1, label.view(-1, 1), 1)\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output = output * self.s\n",
        "\n",
        "        loss = self.ce(output, label)\n",
        "        prec1 = accuracy(output.detach(), label.detach(), topk=(1,))[0]\n",
        "\n",
        "        return loss, prec1"
      ],
      "metadata": {
        "id": "5wDRZFKG6I0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "euZ5jFWqhgIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv1dReluBn(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=True):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, dilation, bias=bias)\n",
        "        self.bn = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.bn(F.relu(self.conv(x)))\n",
        "\n",
        "class Res2Conv1dReluBn(nn.Module):\n",
        "    '''\n",
        "    in_channels == out_channels == channels\n",
        "    '''\n",
        "\n",
        "    def __init__(self, channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=True, scale=4):\n",
        "        super().__init__()\n",
        "        assert channels % scale == 0, \"{} % {} != 0\".format(channels, scale)\n",
        "        self.scale = scale\n",
        "        self.width = channels // scale\n",
        "        self.nums = scale if scale == 1 else scale - 1\n",
        "\n",
        "        self.convs = []\n",
        "        self.bns = []\n",
        "        for i in range(self.nums):\n",
        "            self.convs.append(nn.Conv1d(self.width, self.width, kernel_size, stride, padding, dilation, bias=bias))\n",
        "            self.bns.append(nn.BatchNorm1d(self.width))\n",
        "        self.convs = nn.ModuleList(self.convs)\n",
        "        self.bns = nn.ModuleList(self.bns)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = []\n",
        "        spx = torch.split(x, self.width, 1)\n",
        "        for i in range(self.nums):\n",
        "            if i == 0:\n",
        "                sp = spx[i]\n",
        "            else:\n",
        "                sp = sp + spx[i]\n",
        "            # Order: conv -> relu -> bn\n",
        "            sp = self.convs[i](sp)\n",
        "            sp = self.bns[i](F.relu(sp))\n",
        "            out.append(sp)\n",
        "        if self.scale != 1:\n",
        "            out.append(spx[self.nums])\n",
        "        out = torch.cat(out, dim=1)\n",
        "\n",
        "        return out\n",
        "\n",
        "class SE_Connect(nn.Module):\n",
        "    def __init__(self, channels, se_bottleneck_dim=128):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(channels, se_bottleneck_dim)\n",
        "        self.linear2 = nn.Linear(se_bottleneck_dim, channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x.mean(dim=2)\n",
        "        out = F.relu(self.linear1(out))\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "        out = x * out.unsqueeze(2)\n",
        "\n",
        "        return out\n",
        "\n",
        "class SE_Res2Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, scale, se_bottleneck_dim):\n",
        "        super().__init__()\n",
        "        self.Conv1dReluBn1 = Conv1dReluBn(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.Res2Conv1dReluBn = Res2Conv1dReluBn(out_channels, kernel_size, stride, padding, dilation, scale=scale)\n",
        "        self.Conv1dReluBn2 = Conv1dReluBn(out_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.SE_Connect = SE_Connect(out_channels, se_bottleneck_dim)\n",
        "\n",
        "        self.shortcut = None\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut = nn.Conv1d(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                kernel_size=1,\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        if self.shortcut:\n",
        "            residual = self.shortcut(x)\n",
        "\n",
        "        x = self.Conv1dReluBn1(x)\n",
        "        x = self.Res2Conv1dReluBn(x)\n",
        "        x = self.Conv1dReluBn2(x)\n",
        "        x = self.SE_Connect(x)\n",
        "\n",
        "        return x + residual\n",
        "\n",
        "class AttentiveStatsPool(nn.Module):\n",
        "    def __init__(self, in_dim, attention_channels=128, global_context_att=False):\n",
        "        super().__init__()\n",
        "        self.global_context_att = global_context_att\n",
        "\n",
        "        # Use Conv1d with stride == 1 rather than Linear, then we don't need to transpose inputs.\n",
        "        if global_context_att:\n",
        "            self.linear1 = nn.Conv1d(in_dim * 3, attention_channels, kernel_size=1)  # equals W and b in the paper\n",
        "        else:\n",
        "            self.linear1 = nn.Conv1d(in_dim, attention_channels, kernel_size=1)  # equals W and b in the paper\n",
        "        self.linear2 = nn.Conv1d(attention_channels, in_dim, kernel_size=1)  # equals V and k in the paper\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.global_context_att:\n",
        "            context_mean = torch.mean(x, dim=-1, keepdim=True).expand_as(x)\n",
        "            context_std = torch.sqrt(torch.var(x, dim=-1, keepdim=True) + 1e-10).expand_as(x)\n",
        "            x_in = torch.cat((x, context_mean, context_std), dim=1)\n",
        "        else:\n",
        "            x_in = x\n",
        "\n",
        "        # DON'T use ReLU here! In experiments, I find ReLU hard to converge.\n",
        "        alpha = torch.tanh(self.linear1(x_in))\n",
        "        # alpha = F.relu(self.linear1(x_in))\n",
        "        alpha = torch.softmax(self.linear2(alpha), dim=2)\n",
        "        mean = torch.sum(alpha * x, dim=2)\n",
        "        residuals = torch.sum(alpha * (x ** 2), dim=2) - mean ** 2\n",
        "        std = torch.sqrt(residuals.clamp(min=1e-9))\n",
        "        return torch.cat([mean, std], dim=1)\n",
        "\n",
        "class ECAPA_TDNN(nn.Module):\n",
        "    def __init__(self, feat_dim=80, channels=512, emb_dim=192, global_context_att=False,\n",
        "                 feat_type='fbank', sr=16000, feature_selection=\"hidden_states\", update_extract=False, config_path=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feat_type = feat_type\n",
        "        self.feature_selection = feature_selection\n",
        "        self.update_extract = update_extract\n",
        "        self.sr = sr\n",
        "\n",
        "        if feat_type == \"fbank\" or feat_type == \"mfcc\":\n",
        "            self.update_extract = False\n",
        "\n",
        "        win_len = int(sr * 0.025)\n",
        "        hop_len = int(sr * 0.01)\n",
        "\n",
        "        if feat_type == 'fbank':\n",
        "            self.feature_extract = trans.MelSpectrogram(sample_rate=sr, n_fft=512, win_length=win_len,\n",
        "                                                        hop_length=hop_len, f_min=0.0, f_max=sr // 2,\n",
        "                                                        pad=0, n_mels=feat_dim)\n",
        "        elif feat_type == 'mfcc':\n",
        "            melkwargs = {\n",
        "                'n_fft': 512,\n",
        "                'win_length': win_len,\n",
        "                'hop_length': hop_len,\n",
        "                'f_min': 0.0,\n",
        "                'f_max': sr // 2,\n",
        "                'pad': 0\n",
        "            }\n",
        "            self.feature_extract = trans.MFCC(sample_rate=sr, n_mfcc=feat_dim, log_mels=False,\n",
        "                                              melkwargs=melkwargs)\n",
        "        else:\n",
        "            if config_path is None:\n",
        "                self.feature_extract = torch.hub.load('s3prl/s3prl', feat_type)\n",
        "            else:\n",
        "                self.feature_extract = UpstreamExpert(config_path)\n",
        "            if len(self.feature_extract.model.encoder.layers) == 24 and hasattr(self.feature_extract.model.encoder.layers[23].self_attn, \"fp32_attention\"):\n",
        "                self.feature_extract.model.encoder.layers[23].self_attn.fp32_attention = False\n",
        "            if len(self.feature_extract.model.encoder.layers) == 24 and hasattr(self.feature_extract.model.encoder.layers[11].self_attn, \"fp32_attention\"):\n",
        "                self.feature_extract.model.encoder.layers[11].self_attn.fp32_attention = False\n",
        "\n",
        "            self.feat_num = self.get_feat_num()\n",
        "            self.feature_weight = nn.Parameter(torch.zeros(self.feat_num))\n",
        "\n",
        "        if feat_type != 'fbank' and feat_type != 'mfcc':\n",
        "            freeze_list = ['final_proj', 'label_embs_concat', 'mask_emb', 'project_q', 'quantizer']\n",
        "            for name, param in self.feature_extract.named_parameters():\n",
        "                for freeze_val in freeze_list:\n",
        "                    if freeze_val in name:\n",
        "                        param.requires_grad = False\n",
        "                        break\n",
        "\n",
        "        if not self.update_extract:\n",
        "            for param in self.feature_extract.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        self.instance_norm = nn.InstanceNorm1d(feat_dim)\n",
        "        # self.channels = [channels] * 4 + [channels * 3]\n",
        "        self.channels = [channels] * 4 + [1536]\n",
        "\n",
        "        self.layer1 = Conv1dReluBn(feat_dim, self.channels[0], kernel_size=5, padding=2)\n",
        "        self.layer2 = SE_Res2Block(self.channels[0], self.channels[1], kernel_size=3, stride=1, padding=2, dilation=2, scale=8, se_bottleneck_dim=128)\n",
        "        self.layer3 = SE_Res2Block(self.channels[1], self.channels[2], kernel_size=3, stride=1, padding=3, dilation=3, scale=8, se_bottleneck_dim=128)\n",
        "        self.layer4 = SE_Res2Block(self.channels[2], self.channels[3], kernel_size=3, stride=1, padding=4, dilation=4, scale=8, se_bottleneck_dim=128)\n",
        "\n",
        "        # self.conv = nn.Conv1d(self.channels[-1], self.channels[-1], kernel_size=1)\n",
        "        cat_channels = channels * 3\n",
        "        self.conv = nn.Conv1d(cat_channels, self.channels[-1], kernel_size=1)\n",
        "        self.pooling = AttentiveStatsPool(self.channels[-1], attention_channels=128, global_context_att=global_context_att)\n",
        "        self.bn = nn.BatchNorm1d(self.channels[-1] * 2)\n",
        "        self.linear = nn.Linear(self.channels[-1] * 2, emb_dim)\n",
        "\n",
        "        # Component part\n",
        "        self.new_component = nn.Sequential(\n",
        "            nn.Linear(256, 256),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.Linear(256, 256),\n",
        "        )\n",
        "\n",
        "    def get_feat_num(self):\n",
        "        self.feature_extract.eval()\n",
        "        wav = [torch.randn(self.sr).to(next(self.feature_extract.parameters()).device)]\n",
        "        with torch.no_grad():\n",
        "            features = self.feature_extract(wav)\n",
        "        select_feature = features[self.feature_selection]\n",
        "        if isinstance(select_feature, (list, tuple)):\n",
        "            return len(select_feature)\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    def get_feat(self, x):\n",
        "        if self.update_extract:\n",
        "            x = self.feature_extract([sample for sample in x])\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                if self.feat_type == 'fbank' or self.feat_type == 'mfcc':\n",
        "                    x = self.feature_extract(x) + 1e-6  # B x feat_dim x time_len\n",
        "                else:\n",
        "                    x = self.feature_extract([sample for sample in x])\n",
        "\n",
        "        if self.feat_type == 'fbank':\n",
        "            x = x.log()\n",
        "\n",
        "        if self.feat_type != \"fbank\" and self.feat_type != \"mfcc\":\n",
        "            x = x[self.feature_selection]\n",
        "            if isinstance(x, (list, tuple)):\n",
        "                x = torch.stack(x, dim=0)\n",
        "            else:\n",
        "                x = x.unsqueeze(0)\n",
        "            norm_weights = F.softmax(self.feature_weight, dim=-1).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "            x = (norm_weights * x).sum(dim=0)\n",
        "            x = torch.transpose(x, 1, 2) + 1e-6\n",
        "\n",
        "        x = self.instance_norm(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.get_feat(x)\n",
        "\n",
        "        out1 = self.layer1(x)\n",
        "        out2 = self.layer2(out1)\n",
        "        out3 = self.layer3(out2)\n",
        "        out4 = self.layer4(out3)\n",
        "\n",
        "        out = torch.cat([out2, out3, out4], dim=1)\n",
        "        out = F.relu(self.conv(out))\n",
        "        out = self.bn(self.pooling(out))\n",
        "        out = self.linear(out)\n",
        "\n",
        "        out = self.new_component(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def ECAPA_TDNN_SMALL(feat_dim, emb_dim=256, feat_type='fbank', sr=16000, feature_selection=\"hidden_states\", update_extract=False, config_path=None):\n",
        "    return ECAPA_TDNN(feat_dim=feat_dim, channels=512, emb_dim=emb_dim,\n",
        "                      feat_type=feat_type, sr=sr, feature_selection=feature_selection, update_extract=update_extract, config_path=config_path)"
      ],
      "metadata": {
        "id": "2BGaCC4vSBEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# update_extract=True\n",
        "# model = ECAPA_TDNN_SMALL(feat_dim=1024, feat_type='wavlm_large', config_path=config_path, update_extract=True)\n",
        "MODEL_LIST = ['ecapa_tdnn', 'hubert_large', 'wav2vec2_xlsr', 'unispeech_sat', \"wavlm_base_plus\", \"wavlm_large\"]\n",
        "\n",
        "def init_model(model_name, checkpoint=None, update_component=False):\n",
        "    if model_name == 'unispeech_sat':\n",
        "        config_path = const_path + 'VerificationVoxCeleb1/unispeech_sat.th'\n",
        "        model = ECAPA_TDNN_SMALL(feat_dim=1024, feat_type='unispeech_sat', config_path=config_path)\n",
        "    elif model_name == 'wavlm_base_plus':\n",
        "        config_path = None\n",
        "        model = ECAPA_TDNN_SMALL(feat_dim=768, feat_type='wavlm_base_plus', config_path=config_path)\n",
        "    elif model_name == 'wavlm_large':\n",
        "        config_path = None\n",
        "        model = ECAPA_TDNN_SMALL(feat_dim=1024, feat_type='wavlm_large', config_path=config_path)\n",
        "        if update_component==True:\n",
        "          for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "          for param in model.new_component.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    elif model_name == 'hubert_large':\n",
        "        config_path = None\n",
        "        model = ECAPA_TDNN_SMALL(feat_dim=1024, feat_type='hubert_large_ll60k', config_path=config_path)\n",
        "    elif model_name == 'wav2vec2_xlsr':\n",
        "        config_path = None\n",
        "        model = ECAPA_TDNN_SMALL(feat_dim=1024, feat_type='wav2vec2_xlsr', config_path=config_path)\n",
        "    else:\n",
        "        model = ECAPA_TDNN_SMALL(feat_dim=40, feat_type='fbank')\n",
        "\n",
        "    if checkpoint is not None:\n",
        "        state_dict = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
        "        model.load_state_dict(state_dict['model'], strict=False)\n",
        "    return model"
      ],
      "metadata": {
        "id": "5YojOet2QcUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Some utilized functions\n",
        "These functions are all copied from voxceleb_trainer: https://github.com/clovaai/voxceleb_trainer/blob/master/tuneThreshold.py\n",
        "'''\n",
        "\n",
        "import os, numpy, torch\n",
        "from sklearn import metrics\n",
        "from operator import itemgetter\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def tuneThresholdfromScore(scores, labels, target_fa, target_fr = None):\n",
        "\n",
        "\tfpr, tpr, thresholds = metrics.roc_curve(labels, scores, pos_label=1)\n",
        "\tfnr = 1 - tpr\n",
        "\ttunedThreshold = [];\n",
        "\tif target_fr:\n",
        "\t\tfor tfr in target_fr:\n",
        "\t\t\tidx = numpy.nanargmin(numpy.absolute((tfr - fnr)))\n",
        "\t\t\ttunedThreshold.append([thresholds[idx], fpr[idx], fnr[idx]])\n",
        "\tfor tfa in target_fa:\n",
        "\t\tidx = numpy.nanargmin(numpy.absolute((tfa - fpr))) # numpy.where(fpr<=tfa)[0][-1]\n",
        "\t\ttunedThreshold.append([thresholds[idx], fpr[idx], fnr[idx]])\n",
        "\tidxE = numpy.nanargmin(numpy.absolute((fnr - fpr)))\n",
        "\teer  = max(fpr[idxE],fnr[idxE])*100\n",
        "\n",
        "\treturn tunedThreshold, eer, fpr, fnr\n",
        "\n",
        "# Creates a list of false-negative rates, a list of false-positive rates\n",
        "# and a list of decision thresholds that give those error-rates.\n",
        "def ComputeErrorRates(scores, labels):\n",
        "\n",
        "      # Sort the scores from smallest to largest, and also get the corresponding\n",
        "      # indexes of the sorted scores.  We will treat the sorted scores as the\n",
        "      # thresholds at which the the error-rates are evaluated.\n",
        "      sorted_indexes, thresholds = zip(*sorted(\n",
        "          [(index, threshold) for index, threshold in enumerate(scores)],\n",
        "          key=itemgetter(1)))\n",
        "      sorted_labels = []\n",
        "      labels = [labels[i] for i in sorted_indexes]\n",
        "      fnrs = []\n",
        "      fprs = []\n",
        "\n",
        "      # At the end of this loop, fnrs[i] is the number of errors made by\n",
        "      # incorrectly rejecting scores less than thresholds[i]. And, fprs[i]\n",
        "      # is the total number of times that we have correctly accepted scores\n",
        "      # greater than thresholds[i].\n",
        "      for i in range(0, len(labels)):\n",
        "          if i == 0:\n",
        "              fnrs.append(labels[i])\n",
        "              fprs.append(1 - labels[i])\n",
        "          else:\n",
        "              fnrs.append(fnrs[i-1] + labels[i])\n",
        "              fprs.append(fprs[i-1] + 1 - labels[i])\n",
        "      fnrs_norm = sum(labels)\n",
        "      fprs_norm = len(labels) - fnrs_norm\n",
        "\n",
        "      # Now divide by the total number of false negative errors to\n",
        "      # obtain the false positive rates across all thresholds\n",
        "      fnrs = [x / float(fnrs_norm) for x in fnrs]\n",
        "\n",
        "      # Divide by the total number of corret positives to get the\n",
        "      # true positive rate.  Subtract these quantities from 1 to\n",
        "      # get the false positive rates.\n",
        "      fprs = [1 - x / float(fprs_norm) for x in fprs]\n",
        "      return fnrs, fprs, thresholds\n",
        "\n",
        "# Computes the minimum of the detection cost function.  The comments refer to\n",
        "# equations in Section 3 of the NIST 2016 Speaker Recognition Evaluation Plan.\n",
        "def ComputeMinDcf(fnrs, fprs, thresholds, p_target, c_miss, c_fa):\n",
        "    min_c_det = float(\"inf\")\n",
        "    min_c_det_threshold = thresholds[0]\n",
        "    for i in range(0, len(fnrs)):\n",
        "        # See Equation (2).  it is a weighted sum of false negative\n",
        "        # and false positive errors.\n",
        "        c_det = c_miss * fnrs[i] * p_target + c_fa * fprs[i] * (1 - p_target)\n",
        "        if c_det < min_c_det:\n",
        "            min_c_det = c_det\n",
        "            min_c_det_threshold = thresholds[i]\n",
        "    # See Equations (3) and (4).  Now we normalize the cost.\n",
        "    c_def = min(c_miss * p_target, c_fa * (1 - p_target))\n",
        "    min_dcf = min_c_det / c_def\n",
        "    return min_dcf, min_c_det_threshold\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "\n",
        "\tmaxk = max(topk)\n",
        "\tbatch_size = target.size(0)\n",
        "\t_, pred = output.topk(maxk, 1, True, True)\n",
        "\tpred = pred.t()\n",
        "\tcorrect = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\tres = []\n",
        "\tfor k in topk:\n",
        "\t\tcorrect_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "\t\tres.append(correct_k.mul_(100.0 / batch_size))\n",
        "\n",
        "\treturn res"
      ],
      "metadata": {
        "id": "Of1m2ryILnpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using optim SGD\n",
        "class ECAPAModel(nn.Module):\n",
        "\tdef __init__(self, lr, lr_decay, C , n_class, m, s, test_step, **kwargs):\n",
        "\t\tsuper(ECAPAModel, self).__init__()\n",
        "\t\t## ECAPA-TDNN\n",
        "\t\tself.speaker_encoder = (init_model('wavlm_large', const_path + 'KLTN/source/wavlm_large/wavlm_large_finetune.pth',update_component=True)).cuda()\n",
        "\t\t## Classifier\n",
        "\t\tself.speaker_loss    = AAMsoftmax(n_class = n_class, m = m, s = s).cuda()\n",
        "\n",
        "\t\tself.optim           = torch.optim.SGD(self.parameters(), lr = lr, weight_decay = 2e-5)\n",
        "\t\tself.scheduler       = torch.optim.lr_scheduler.StepLR(self.optim, step_size = test_step, gamma=lr_decay)\n",
        "\t\tprint(time.strftime(\"%m-%d %H:%M:%S\") + \" Model para number = %.2f\"%(sum(param.numel() for param in self.speaker_encoder.parameters())))\n",
        "\n",
        "\tdef train_network(self, epoch, loader):\n",
        "\t\tself.train()\n",
        "\t\t## Update the learning rate based on the current epcoh\n",
        "\t\tself.scheduler.step(epoch - 1)\n",
        "\t\tindex, top1, loss = 0, 0, 0\n",
        "\t\tlr = self.optim.param_groups[0]['lr']\n",
        "\t\tfor num, (data, labels) in tqdm.tqdm(enumerate(loader, start = 1)):\n",
        "\t\t\tself.zero_grad()\n",
        "\t\t\tlabels            = torch.LongTensor(labels).cuda()\n",
        "\t\t\tspeaker_embedding = self.speaker_encoder.forward(data.cuda())\n",
        "\t\t\tnloss, prec       = self.speaker_loss.forward(speaker_embedding, labels)\n",
        "\t\t\tnloss.backward()\n",
        "\t\t\tself.optim.step()\n",
        "\t\t\tindex += len(labels)\n",
        "\t\t\ttop1 += prec\n",
        "\t\t\tloss += nloss.detach().cpu().numpy()\n",
        "\t\t\tprint(time.strftime(\"%m-%d %H:%M:%S\") + \\\n",
        "\t\t\t\" [%2d] Lr: %5f, Training: %.2f%%, \"    %(epoch, lr, 100 * (num / loader.__len__())) + \\\n",
        "\t\t\t\" Loss: %.5f, ACC: %2.2f%% \\r\"        %(loss/(num), top1/index*len(labels)))\n",
        "\t\t\t# sys.stderr.flush()\n",
        "\t\tprint(\"\\n\")\n",
        "\t\treturn loss/num, lr, top1/index*len(labels)\n",
        "\n",
        "\tdef eval_network(self, eval_list, eval_path):\n",
        "\t\tself.eval()\n",
        "\t\tfiles = []\n",
        "\t\tembeddings = {}\n",
        "\t\tlines = open(eval_list).read().splitlines()\n",
        "\t\tfor line in lines:\n",
        "\t\t\tfiles.append(line.split()[1])\n",
        "\t\t\tfiles.append(line.split()[2])\n",
        "\t\tsetfiles = list(set(files))\n",
        "\t\tsetfiles.sort()\n",
        "\n",
        "\t\tfor idx, file in tqdm.tqdm(enumerate(setfiles), total = len(setfiles)):\n",
        "\t\t\taudio, _  = soundfile.read(os.path.join(eval_path, file))\n",
        "\t\t\t# Full utterance\n",
        "\t\t\tdata_1 = torch.FloatTensor(numpy.stack([audio],axis=0)).cuda()\n",
        "\n",
        "\t\t\t# Spliited utterance matrix\n",
        "\t\t\tmax_audio = 300 * 160 + 240\n",
        "\t\t\tif audio.shape[0] <= max_audio:\n",
        "\t\t\t\tshortage = max_audio - audio.shape[0]\n",
        "\t\t\t\taudio = numpy.pad(audio, (0, shortage), 'wrap')\n",
        "\t\t\tfeats = []\n",
        "\t\t\tstartframe = numpy.linspace(0, audio.shape[0]-max_audio, num=5)\n",
        "\t\t\tfor asf in startframe:\n",
        "\t\t\t\tfeats.append(audio[int(asf):int(asf)+max_audio])\n",
        "\t\t\tfeats = numpy.stack(feats, axis = 0).astype(numpy.float)\n",
        "\t\t\tdata_2 = torch.FloatTensor(feats).cuda()\n",
        "\t\t\t# Speaker embeddings\n",
        "\t\t\twith torch.no_grad():\n",
        "\t\t\t\tembedding_1 = self.speaker_encoder.forward(data_1)\n",
        "\t\t\t\tembedding_1 = F.normalize(embedding_1, p=2, dim=1)\n",
        "\t\t\t\tembedding_2 = self.speaker_encoder.forward(data_2)\n",
        "\t\t\t\tembedding_2 = F.normalize(embedding_2, p=2, dim=1)\n",
        "\t\t\tembeddings[file] = [embedding_1, embedding_2]\n",
        "\t\tscores, labels  = [], []\n",
        "\n",
        "\t\tfor line in lines:\n",
        "\t\t\tembedding_11, embedding_12 = embeddings[line.split()[1]]\n",
        "\t\t\tembedding_21, embedding_22 = embeddings[line.split()[2]]\n",
        "\t\t\t# Compute the scores\n",
        "\t\t\tscore_1 = torch.mean(torch.matmul(embedding_11, embedding_21.T)) # higher is positive\n",
        "\t\t\tscore_2 = torch.mean(torch.matmul(embedding_12, embedding_22.T))\n",
        "\t\t\tscore = (score_1 + score_2) / 2\n",
        "\t\t\tscore = score.detach().cpu().numpy()\n",
        "\t\t\tscores.append(score)\n",
        "\t\t\tlabels.append(int(line.split()[0]))\n",
        "\n",
        "\t\t# Coumpute EER and minDCF\n",
        "\t\tEER = tuneThresholdfromScore(scores, labels, [1, 0.1])[1]\n",
        "\t\tfnrs, fprs, thresholds = ComputeErrorRates(scores, labels)\n",
        "\t\tminDCF, _ = ComputeMinDcf(fnrs, fprs, thresholds, 0.05, 1, 1)\n",
        "\n",
        "\t\treturn EER, minDCF\n",
        "\n",
        "\tdef save_parameters(self, path):\n",
        "\t\ttorch.save(self.state_dict(), path)\n",
        "\n",
        "\tdef load_parameters(self, path):\n",
        "\t\tself_state = self.state_dict()\n",
        "\t\tloaded_state = torch.load(path)\n",
        "\t\tfor name, param in loaded_state.items():\n",
        "\t\t\torigname = name\n",
        "\t\t\tif name not in self_state:\n",
        "\t\t\t\tname = name.replace(\"module.\", \"\")\n",
        "\t\t\t\tif name not in self_state:\n",
        "\t\t\t\t\tprint(\"%s is not in the model.\"%origname)\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\tif self_state[name].size() != loaded_state[origname].size():\n",
        "\t\t\t\tprint(\"Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state[origname].size()))\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tself_state[name].copy_(param)"
      ],
      "metadata": {
        "id": "exxG17f_F4CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "wncK0zwHjkKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ECAPAModel(lr, lr_decay, C , n_class, m, s, test_step)"
      ],
      "metadata": {
        "id": "A32eegykLt_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74acf9d5-9a9f-40a1-d818-6909a4145034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/s3prl/s3prl/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: https://huggingface.co/s3prl/converted_ckpts/resolve/main/wavlm_large.pt\n",
            "Destination: /root/.cache/s3prl/download/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt\n",
            "100%|██████████| 1.18G/1.18G [00:14<00:00, 85.6MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:04:37 Model para number = 324061337.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.load_parameters(\"/content/gdrive/MyDrive/KLTN/source/wavlm_large/component/model_0047.model\")"
      ],
      "metadata": {
        "id": "Id3SRaXPBdHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_save_path    = \"/content/gdrive/MyDrive/KLTN/source/wavlm_large/component/score.txt\"\n",
        "model_save_path    = \"/content/gdrive/MyDrive/KLTN/source/wavlm_large/component\"\n",
        "EERs = []\n",
        "score_file = open(score_save_path, \"a+\")\n",
        "while(1):\n",
        "  print(f\"Epoch: {epoch}\")\n",
        "  loss, lr, acc = model.train_network(epoch, loader = trainLoader)\n",
        "  if epoch % test_step == 0:\n",
        "    model.save_parameters(model_save_path + \"/model_%04d.model\"%epoch)\n",
        "    EERs.append(model.eval_network(eval_list = eval_list, eval_path = eval_path)[0])\n",
        "    print(time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"%d epoch, ACC %2.2f%%, EER %2.2f%%, bestEER %2.2f%%\"%(epoch, acc, EERs[-1], min(EERs)))\n",
        "    score_file.write(\"%d epoch, LR %f, LOSS %f, ACC %2.2f%%, EER %2.2f%%, bestEER %2.2f%%\\n\"%(epoch, lr, loss, acc, EERs[-1], min(EERs)))\n",
        "    score_file.flush()\n",
        "  if epoch >= max_epoch:\n",
        "    quit()\n",
        "  epoch += 1"
      ],
      "metadata": {
        "id": "eAZQXqgcMF3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6f45ad-459c-4be9-f2df-9e2c4b047bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "1it [01:43, 103.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:06:53 [48] Lr: 0.000239, Training: 1.75%,  Loss: 2.57033, ACC: 48.67% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [01:48, 45.39s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:06:58 [48] Lr: 0.000239, Training: 3.51%,  Loss: 2.65042, ACC: 49.33% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [02:51, 53.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:08:02 [48] Lr: 0.000239, Training: 5.26%,  Loss: 2.62491, ACC: 50.00% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [02:56, 34.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:08:07 [48] Lr: 0.000239, Training: 7.02%,  Loss: 2.59828, ACC: 50.67% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [04:06, 47.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:09:17 [48] Lr: 0.000239, Training: 8.77%,  Loss: 2.57724, ACC: 51.07% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [04:11, 32.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:09:22 [48] Lr: 0.000239, Training: 10.53%,  Loss: 2.57316, ACC: 50.56% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [05:20, 44.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:10:30 [48] Lr: 0.000239, Training: 12.28%,  Loss: 2.51475, ACC: 51.81% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [05:25, 31.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:10:35 [48] Lr: 0.000239, Training: 14.04%,  Loss: 2.51170, ACC: 51.42% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [06:33, 43.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:11:44 [48] Lr: 0.000239, Training: 15.79%,  Loss: 2.49430, ACC: 51.56% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [06:39, 31.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:11:49 [48] Lr: 0.000239, Training: 17.54%,  Loss: 2.49800, ACC: 51.40% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [07:44, 42.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:12:55 [48] Lr: 0.000239, Training: 19.30%,  Loss: 2.50886, ACC: 51.64% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [07:50, 30.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:13:00 [48] Lr: 0.000239, Training: 21.05%,  Loss: 2.51796, ACC: 51.44% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [08:56, 41.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:14:07 [48] Lr: 0.000239, Training: 22.81%,  Loss: 2.52537, ACC: 51.49% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r14it [09:02, 30.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:14:13 [48] Lr: 0.000239, Training: 24.56%,  Loss: 2.55188, ACC: 51.62% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [10:10, 42.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:15:21 [48] Lr: 0.000239, Training: 26.32%,  Loss: 2.56939, ACC: 51.42% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r16it [10:16, 31.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:15:27 [48] Lr: 0.000239, Training: 28.07%,  Loss: 2.57620, ACC: 51.25% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [11:23, 41.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:16:34 [48] Lr: 0.000239, Training: 29.82%,  Loss: 2.55751, ACC: 51.49% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r18it [11:28, 30.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:16:39 [48] Lr: 0.000239, Training: 31.58%,  Loss: 2.58124, ACC: 50.96% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r19it [12:34, 41.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:17:45 [48] Lr: 0.000239, Training: 33.33%,  Loss: 2.57843, ACC: 51.09% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r20it [12:40, 30.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:17:51 [48] Lr: 0.000239, Training: 35.09%,  Loss: 2.58715, ACC: 51.00% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [13:49, 42.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:19:00 [48] Lr: 0.000239, Training: 36.84%,  Loss: 2.57702, ACC: 51.21% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r22it [13:54, 31.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:19:05 [48] Lr: 0.000239, Training: 38.60%,  Loss: 2.55476, ACC: 51.36% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r23it [14:59, 41.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:20:10 [48] Lr: 0.000239, Training: 40.35%,  Loss: 2.55190, ACC: 51.48% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r24it [15:05, 30.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:20:16 [48] Lr: 0.000239, Training: 42.11%,  Loss: 2.56232, ACC: 51.31% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r25it [16:11, 41.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:21:21 [48] Lr: 0.000239, Training: 43.86%,  Loss: 2.56550, ACC: 51.41% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r26it [16:16, 30.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:21:27 [48] Lr: 0.000239, Training: 45.61%,  Loss: 2.56349, ACC: 51.51% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r27it [17:21, 40.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:22:32 [48] Lr: 0.000239, Training: 47.37%,  Loss: 2.55924, ACC: 51.78% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r28it [17:27, 30.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:22:38 [48] Lr: 0.000239, Training: 49.12%,  Loss: 2.57019, ACC: 51.57% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r29it [18:31, 40.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:23:42 [48] Lr: 0.000239, Training: 50.88%,  Loss: 2.55964, ACC: 51.79% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r30it [18:37, 29.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:23:47 [48] Lr: 0.000239, Training: 52.63%,  Loss: 2.55444, ACC: 52.02% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r31it [19:43, 40.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:24:53 [48] Lr: 0.000239, Training: 54.39%,  Loss: 2.55080, ACC: 51.96% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r32it [19:48, 30.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:24:59 [48] Lr: 0.000239, Training: 56.14%,  Loss: 2.54349, ACC: 52.08% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r33it [20:52, 40.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:26:02 [48] Lr: 0.000239, Training: 57.89%,  Loss: 2.54525, ACC: 52.16% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r34it [20:57, 29.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:26:08 [48] Lr: 0.000239, Training: 59.65%,  Loss: 2.54865, ACC: 52.02% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r35it [22:02, 40.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:27:13 [48] Lr: 0.000239, Training: 61.40%,  Loss: 2.55334, ACC: 51.96% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r36it [22:08, 29.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:27:18 [48] Lr: 0.000239, Training: 63.16%,  Loss: 2.55279, ACC: 51.94% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r37it [23:10, 39.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:28:21 [48] Lr: 0.000239, Training: 64.91%,  Loss: 2.54604, ACC: 51.93% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r38it [23:16, 29.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:28:27 [48] Lr: 0.000239, Training: 66.67%,  Loss: 2.53738, ACC: 52.19% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r39it [24:19, 39.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:29:30 [48] Lr: 0.000239, Training: 68.42%,  Loss: 2.53334, ACC: 52.10% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r40it [24:25, 29.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:29:36 [48] Lr: 0.000239, Training: 70.18%,  Loss: 2.53152, ACC: 52.17% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r41it [25:29, 39.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:30:39 [48] Lr: 0.000239, Training: 71.93%,  Loss: 2.53290, ACC: 52.11% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r42it [25:34, 29.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:30:45 [48] Lr: 0.000239, Training: 73.68%,  Loss: 2.52863, ACC: 52.11% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r43it [26:39, 40.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:31:50 [48] Lr: 0.000239, Training: 75.44%,  Loss: 2.52370, ACC: 52.20% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r44it [26:44, 29.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:31:55 [48] Lr: 0.000239, Training: 77.19%,  Loss: 2.52609, ACC: 52.18% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r45it [27:48, 39.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:32:59 [48] Lr: 0.000239, Training: 78.95%,  Loss: 2.52722, ACC: 52.16% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r46it [27:54, 29.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:33:05 [48] Lr: 0.000239, Training: 80.70%,  Loss: 2.53121, ACC: 52.12% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r47it [28:58, 40.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:34:09 [48] Lr: 0.000239, Training: 82.46%,  Loss: 2.52114, ACC: 52.21% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r48it [29:04, 29.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:34:14 [48] Lr: 0.000239, Training: 84.21%,  Loss: 2.53823, ACC: 51.90% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r49it [30:08, 39.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:35:18 [48] Lr: 0.000239, Training: 85.96%,  Loss: 2.52974, ACC: 52.01% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r50it [30:13, 29.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:35:24 [48] Lr: 0.000239, Training: 87.72%,  Loss: 2.52949, ACC: 51.97% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r51it [31:16, 39.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:36:27 [48] Lr: 0.000239, Training: 89.47%,  Loss: 2.53289, ACC: 52.01% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r52it [31:21, 29.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:36:32 [48] Lr: 0.000239, Training: 91.23%,  Loss: 2.52939, ACC: 51.99% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r53it [32:25, 39.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:37:35 [48] Lr: 0.000239, Training: 92.98%,  Loss: 2.53131, ACC: 51.95% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r54it [32:30, 29.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:37:41 [48] Lr: 0.000239, Training: 94.74%,  Loss: 2.53054, ACC: 51.91% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r55it [33:34, 39.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:38:44 [48] Lr: 0.000239, Training: 96.49%,  Loss: 2.53279, ACC: 51.87% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r56it [33:39, 29.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:38:50 [48] Lr: 0.000239, Training: 98.25%,  Loss: 2.53295, ACC: 51.80% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "57it [34:23, 36.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:39:34 [48] Lr: 0.000239, Training: 100.00%,  Loss: 2.53757, ACC: 37.80% \r\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/973 [00:00<?, ?it/s]<ipython-input-15-b61162519fae>:62: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  feats = numpy.stack(feats, axis = 0).astype(numpy.float)\n",
            "100%|██████████| 973/973 [10:23<00:00,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-14 17:50:07 48 epoch, ACC 37.80%, EER 5.93%, bestEER 5.93%\n",
            "Epoch: 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "1it [00:06,  6.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:50:14 [49] Lr: 0.000232, Training: 1.75%,  Loss: 2.37232, ACC: 56.67% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:11,  5.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:50:20 [49] Lr: 0.000232, Training: 3.51%,  Loss: 2.10619, ACC: 58.67% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:17,  5.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:50:25 [49] Lr: 0.000232, Training: 5.26%,  Loss: 2.38690, ACC: 52.00% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [00:23,  5.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:50:31 [49] Lr: 0.000232, Training: 7.02%,  Loss: 2.44437, ACC: 50.67% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [00:28,  5.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:50:36 [49] Lr: 0.000232, Training: 8.77%,  Loss: 2.50928, ACC: 51.07% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [00:33,  5.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:50:42 [49] Lr: 0.000232, Training: 10.53%,  Loss: 2.48505, ACC: 52.00% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [00:39,  5.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:50:47 [49] Lr: 0.000232, Training: 12.28%,  Loss: 2.46354, ACC: 52.29% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [00:44,  5.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:50:53 [49] Lr: 0.000232, Training: 14.04%,  Loss: 2.51439, ACC: 51.92% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [00:50,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:50:58 [49] Lr: 0.000232, Training: 15.79%,  Loss: 2.51428, ACC: 52.22% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [00:55,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:51:03 [49] Lr: 0.000232, Training: 17.54%,  Loss: 2.50307, ACC: 52.13% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [01:00,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:51:09 [49] Lr: 0.000232, Training: 19.30%,  Loss: 2.48846, ACC: 51.64% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [01:06,  5.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:51:14 [49] Lr: 0.000232, Training: 21.05%,  Loss: 2.49259, ACC: 52.17% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [01:11,  5.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:51:20 [49] Lr: 0.000232, Training: 22.81%,  Loss: 2.47298, ACC: 52.26% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r14it [01:17,  5.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:51:25 [49] Lr: 0.000232, Training: 24.56%,  Loss: 2.50792, ACC: 51.71% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [01:22,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:51:30 [49] Lr: 0.000232, Training: 26.32%,  Loss: 2.51709, ACC: 51.51% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r16it [01:28,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:51:36 [49] Lr: 0.000232, Training: 28.07%,  Loss: 2.53050, ACC: 51.21% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [01:33,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:51:41 [49] Lr: 0.000232, Training: 29.82%,  Loss: 2.50581, ACC: 51.41% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r18it [01:38,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:51:47 [49] Lr: 0.000232, Training: 31.58%,  Loss: 2.49360, ACC: 51.56% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r19it [01:44,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:51:52 [49] Lr: 0.000232, Training: 33.33%,  Loss: 2.50171, ACC: 51.61% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r20it [01:49,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:51:58 [49] Lr: 0.000232, Training: 35.09%,  Loss: 2.49826, ACC: 51.70% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [01:55,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:52:03 [49] Lr: 0.000232, Training: 36.84%,  Loss: 2.50748, ACC: 51.59% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r22it [02:00,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:52:09 [49] Lr: 0.000232, Training: 38.60%,  Loss: 2.50687, ACC: 51.52% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r23it [02:06,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:52:14 [49] Lr: 0.000232, Training: 40.35%,  Loss: 2.50159, ACC: 51.62% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r24it [02:11,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:52:19 [49] Lr: 0.000232, Training: 42.11%,  Loss: 2.49206, ACC: 51.92% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r25it [02:16,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:52:25 [49] Lr: 0.000232, Training: 43.86%,  Loss: 2.48639, ACC: 52.00% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r26it [02:22,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:52:30 [49] Lr: 0.000232, Training: 45.61%,  Loss: 2.47532, ACC: 52.10% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r27it [02:27,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:52:36 [49] Lr: 0.000232, Training: 47.37%,  Loss: 2.48202, ACC: 52.15% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r28it [02:33,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:52:41 [49] Lr: 0.000232, Training: 49.12%,  Loss: 2.47647, ACC: 52.43% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r29it [02:38,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:52:47 [49] Lr: 0.000232, Training: 50.88%,  Loss: 2.48724, ACC: 52.25% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r30it [02:44,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:52:52 [49] Lr: 0.000232, Training: 52.63%,  Loss: 2.48341, ACC: 52.42% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r31it [02:49,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:52:58 [49] Lr: 0.000232, Training: 54.39%,  Loss: 2.49680, ACC: 52.37% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r32it [02:55,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:53:03 [49] Lr: 0.000232, Training: 56.14%,  Loss: 2.49337, ACC: 52.38% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r33it [03:00,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:53:08 [49] Lr: 0.000232, Training: 57.89%,  Loss: 2.48376, ACC: 52.59% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r34it [03:06,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:53:14 [49] Lr: 0.000232, Training: 59.65%,  Loss: 2.47889, ACC: 52.75% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r35it [03:11,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:53:19 [49] Lr: 0.000232, Training: 61.40%,  Loss: 2.48769, ACC: 52.63% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r36it [03:16,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:53:25 [49] Lr: 0.000232, Training: 63.16%,  Loss: 2.48431, ACC: 52.57% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r37it [03:22,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:53:30 [49] Lr: 0.000232, Training: 64.91%,  Loss: 2.48049, ACC: 52.59% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r38it [03:27,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:53:36 [49] Lr: 0.000232, Training: 66.67%,  Loss: 2.48078, ACC: 52.63% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r39it [03:33,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:53:41 [49] Lr: 0.000232, Training: 68.42%,  Loss: 2.48616, ACC: 52.53% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r40it [03:38,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:53:47 [49] Lr: 0.000232, Training: 70.18%,  Loss: 2.48289, ACC: 52.55% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r41it [03:44,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:53:52 [49] Lr: 0.000232, Training: 71.93%,  Loss: 2.48574, ACC: 52.57% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r42it [03:49,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:53:57 [49] Lr: 0.000232, Training: 73.68%,  Loss: 2.49073, ACC: 52.49% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r43it [03:54,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:54:03 [49] Lr: 0.000232, Training: 75.44%,  Loss: 2.49177, ACC: 52.47% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r44it [04:00,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:54:08 [49] Lr: 0.000232, Training: 77.19%,  Loss: 2.49409, ACC: 52.45% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r45it [04:05,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:54:14 [49] Lr: 0.000232, Training: 78.95%,  Loss: 2.49536, ACC: 52.41% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r46it [04:11,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:54:19 [49] Lr: 0.000232, Training: 80.70%,  Loss: 2.49757, ACC: 52.42% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r47it [04:16,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:54:24 [49] Lr: 0.000232, Training: 82.46%,  Loss: 2.49215, ACC: 52.50% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r48it [04:22,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:54:30 [49] Lr: 0.000232, Training: 84.21%,  Loss: 2.50206, ACC: 52.38% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r49it [04:27,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:54:35 [49] Lr: 0.000232, Training: 85.96%,  Loss: 2.49922, ACC: 52.42% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r50it [04:32,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:54:41 [49] Lr: 0.000232, Training: 87.72%,  Loss: 2.49812, ACC: 52.48% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r51it [04:38,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:54:46 [49] Lr: 0.000232, Training: 89.47%,  Loss: 2.49974, ACC: 52.46% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r52it [04:43,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:54:52 [49] Lr: 0.000232, Training: 91.23%,  Loss: 2.50223, ACC: 52.41% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r53it [04:49,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:54:57 [49] Lr: 0.000232, Training: 92.98%,  Loss: 2.51063, ACC: 52.44% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r54it [04:54,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:55:02 [49] Lr: 0.000232, Training: 94.74%,  Loss: 2.51837, ACC: 52.40% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r55it [04:59,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:55:08 [49] Lr: 0.000232, Training: 96.49%,  Loss: 2.51829, ACC: 52.30% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r56it [05:05,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:55:13 [49] Lr: 0.000232, Training: 98.25%,  Loss: 2.51344, ACC: 52.42% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "57it [05:09,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 17:55:17 [49] Lr: 0.000232, Training: 100.00%,  Loss: 2.51073, ACC: 38.28% \r\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/973 [00:00<?, ?it/s]<ipython-input-15-b61162519fae>:62: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  feats = numpy.stack(feats, axis = 0).astype(numpy.float)\n",
            "100%|██████████| 973/973 [04:27<00:00,  3.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-14 17:59:55 49 epoch, ACC 38.28%, EER 5.85%, bestEER 5.85%\n",
            "Epoch: 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "1it [00:06,  6.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:00:01 [50] Lr: 0.000225, Training: 1.75%,  Loss: 2.22073, ACC: 52.67% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:11,  5.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:00:07 [50] Lr: 0.000225, Training: 3.51%,  Loss: 2.20871, ACC: 54.00% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:17,  5.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:00:12 [50] Lr: 0.000225, Training: 5.26%,  Loss: 2.27142, ACC: 54.44% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [00:22,  5.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:00:18 [50] Lr: 0.000225, Training: 7.02%,  Loss: 2.50884, ACC: 51.50% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [00:28,  5.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:00:23 [50] Lr: 0.000225, Training: 8.77%,  Loss: 2.48983, ACC: 52.00% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [00:33,  5.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:00:29 [50] Lr: 0.000225, Training: 10.53%,  Loss: 2.50094, ACC: 52.22% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [00:39,  5.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:00:34 [50] Lr: 0.000225, Training: 12.28%,  Loss: 2.48348, ACC: 52.76% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [00:44,  5.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:00:39 [50] Lr: 0.000225, Training: 14.04%,  Loss: 2.47522, ACC: 52.33% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [00:49,  5.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:00:45 [50] Lr: 0.000225, Training: 15.79%,  Loss: 2.48855, ACC: 52.07% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [00:55,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:00:50 [50] Lr: 0.000225, Training: 17.54%,  Loss: 2.50647, ACC: 51.93% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [01:00,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:00:56 [50] Lr: 0.000225, Training: 19.30%,  Loss: 2.52436, ACC: 51.70% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [01:06,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:01:01 [50] Lr: 0.000225, Training: 21.05%,  Loss: 2.50678, ACC: 51.89% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [01:11,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:01:07 [50] Lr: 0.000225, Training: 22.81%,  Loss: 2.49624, ACC: 52.26% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r14it [01:16,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:01:12 [50] Lr: 0.000225, Training: 24.56%,  Loss: 2.52439, ACC: 52.24% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [01:22,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:01:17 [50] Lr: 0.000225, Training: 26.32%,  Loss: 2.50350, ACC: 52.67% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r16it [01:27,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:01:23 [50] Lr: 0.000225, Training: 28.07%,  Loss: 2.50663, ACC: 52.17% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [01:33,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:01:28 [50] Lr: 0.000225, Training: 29.82%,  Loss: 2.48250, ACC: 52.67% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r18it [01:38,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:01:34 [50] Lr: 0.000225, Training: 31.58%,  Loss: 2.48024, ACC: 52.52% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r19it [01:44,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:01:39 [50] Lr: 0.000225, Training: 33.33%,  Loss: 2.50738, ACC: 51.93% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r20it [01:49,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:01:44 [50] Lr: 0.000225, Training: 35.09%,  Loss: 2.50592, ACC: 52.03% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [01:54,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:01:50 [50] Lr: 0.000225, Training: 36.84%,  Loss: 2.51861, ACC: 51.68% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r22it [02:00,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:01:55 [50] Lr: 0.000225, Training: 38.60%,  Loss: 2.49785, ACC: 51.85% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r23it [02:05,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:02:01 [50] Lr: 0.000225, Training: 40.35%,  Loss: 2.49066, ACC: 51.80% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r24it [02:11,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:02:06 [50] Lr: 0.000225, Training: 42.11%,  Loss: 2.50716, ACC: 51.58% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r25it [02:16,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:02:12 [50] Lr: 0.000225, Training: 43.86%,  Loss: 2.52245, ACC: 51.55% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r26it [02:22,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:02:17 [50] Lr: 0.000225, Training: 45.61%,  Loss: 2.52197, ACC: 51.69% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r27it [02:27,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:02:22 [50] Lr: 0.000225, Training: 47.37%,  Loss: 2.53419, ACC: 51.56% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r28it [02:32,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:02:28 [50] Lr: 0.000225, Training: 49.12%,  Loss: 2.53263, ACC: 51.81% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r29it [02:38,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:02:33 [50] Lr: 0.000225, Training: 50.88%,  Loss: 2.53231, ACC: 51.86% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r30it [02:43,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:02:39 [50] Lr: 0.000225, Training: 52.63%,  Loss: 2.51464, ACC: 52.22% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r31it [02:49,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:02:44 [50] Lr: 0.000225, Training: 54.39%,  Loss: 2.50217, ACC: 52.45% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r32it [02:54,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:02:50 [50] Lr: 0.000225, Training: 56.14%,  Loss: 2.50720, ACC: 52.38% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r33it [03:00,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:02:55 [50] Lr: 0.000225, Training: 57.89%,  Loss: 2.50902, ACC: 52.20% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r34it [03:05,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:03:01 [50] Lr: 0.000225, Training: 59.65%,  Loss: 2.50008, ACC: 52.41% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r35it [03:10,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:03:06 [50] Lr: 0.000225, Training: 61.40%,  Loss: 2.49909, ACC: 52.40% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r36it [03:16,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:03:11 [50] Lr: 0.000225, Training: 63.16%,  Loss: 2.48576, ACC: 52.63% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r37it [03:21,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:03:17 [50] Lr: 0.000225, Training: 64.91%,  Loss: 2.48798, ACC: 52.58% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r38it [03:27,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:03:22 [50] Lr: 0.000225, Training: 66.67%,  Loss: 2.49595, ACC: 52.49% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r39it [03:32,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:03:28 [50] Lr: 0.000225, Training: 68.42%,  Loss: 2.49091, ACC: 52.56% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r40it [03:38,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:03:33 [50] Lr: 0.000225, Training: 70.18%,  Loss: 2.48485, ACC: 52.68% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r41it [03:43,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:03:38 [50] Lr: 0.000225, Training: 71.93%,  Loss: 2.48266, ACC: 52.76% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r42it [03:48,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:03:44 [50] Lr: 0.000225, Training: 73.68%,  Loss: 2.48434, ACC: 52.76% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r43it [03:54,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:03:49 [50] Lr: 0.000225, Training: 75.44%,  Loss: 2.48342, ACC: 52.84% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r44it [03:59,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:03:55 [50] Lr: 0.000225, Training: 77.19%,  Loss: 2.48423, ACC: 52.88% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r45it [04:05,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:04:00 [50] Lr: 0.000225, Training: 78.95%,  Loss: 2.48018, ACC: 52.89% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r46it [04:10,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:04:06 [50] Lr: 0.000225, Training: 80.70%,  Loss: 2.47783, ACC: 52.87% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r47it [04:15,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:04:11 [50] Lr: 0.000225, Training: 82.46%,  Loss: 2.47574, ACC: 52.82% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r48it [04:21,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:04:16 [50] Lr: 0.000225, Training: 84.21%,  Loss: 2.48552, ACC: 52.78% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r49it [04:26,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:04:22 [50] Lr: 0.000225, Training: 85.96%,  Loss: 2.48754, ACC: 52.82% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r50it [04:32,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:04:27 [50] Lr: 0.000225, Training: 87.72%,  Loss: 2.48391, ACC: 52.84% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r51it [04:37,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:04:33 [50] Lr: 0.000225, Training: 89.47%,  Loss: 2.47943, ACC: 52.84% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r52it [04:43,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:04:38 [50] Lr: 0.000225, Training: 91.23%,  Loss: 2.47972, ACC: 52.86% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r53it [04:48,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:04:44 [50] Lr: 0.000225, Training: 92.98%,  Loss: 2.47853, ACC: 52.86% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r54it [04:53,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:04:49 [50] Lr: 0.000225, Training: 94.74%,  Loss: 2.48072, ACC: 52.88% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r55it [04:59,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:04:54 [50] Lr: 0.000225, Training: 96.49%,  Loss: 2.47802, ACC: 52.91% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r56it [05:04,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:05:00 [50] Lr: 0.000225, Training: 98.25%,  Loss: 2.48386, ACC: 52.86% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "57it [05:08,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:05:04 [50] Lr: 0.000225, Training: 100.00%,  Loss: 2.48570, ACC: 38.51% \r\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/973 [00:00<?, ?it/s]<ipython-input-15-b61162519fae>:62: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  feats = numpy.stack(feats, axis = 0).astype(numpy.float)\n",
            "100%|██████████| 973/973 [04:26<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-14 18:09:40 50 epoch, ACC 38.51%, EER 5.87%, bestEER 5.85%\n",
            "Epoch: 51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "1it [00:06,  6.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:09:47 [51] Lr: 0.000218, Training: 1.75%,  Loss: 2.33769, ACC: 57.33% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:11,  5.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:09:52 [51] Lr: 0.000218, Training: 3.51%,  Loss: 2.21778, ACC: 57.00% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:17,  5.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:09:57 [51] Lr: 0.000218, Training: 5.26%,  Loss: 2.34035, ACC: 54.89% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [00:22,  5.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:10:03 [51] Lr: 0.000218, Training: 7.02%,  Loss: 2.35495, ACC: 54.83% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [00:28,  5.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:10:08 [51] Lr: 0.000218, Training: 8.77%,  Loss: 2.30340, ACC: 56.40% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [00:33,  5.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:10:14 [51] Lr: 0.000218, Training: 10.53%,  Loss: 2.31152, ACC: 56.22% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [00:38,  5.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:10:19 [51] Lr: 0.000218, Training: 12.28%,  Loss: 2.30794, ACC: 56.00% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [00:44,  5.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:10:25 [51] Lr: 0.000218, Training: 14.04%,  Loss: 2.35463, ACC: 54.92% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [00:49,  5.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:10:30 [51] Lr: 0.000218, Training: 15.79%,  Loss: 2.38221, ACC: 54.44% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [00:55,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:10:36 [51] Lr: 0.000218, Training: 17.54%,  Loss: 2.40152, ACC: 54.27% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [01:00,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:10:41 [51] Lr: 0.000218, Training: 19.30%,  Loss: 2.37769, ACC: 54.55% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [01:05,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:10:46 [51] Lr: 0.000218, Training: 21.05%,  Loss: 2.38384, ACC: 54.67% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [01:11,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:10:52 [51] Lr: 0.000218, Training: 22.81%,  Loss: 2.40326, ACC: 54.41% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r14it [01:16,  5.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:10:57 [51] Lr: 0.000218, Training: 24.56%,  Loss: 2.37284, ACC: 54.81% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [01:22,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:11:03 [51] Lr: 0.000218, Training: 26.32%,  Loss: 2.38033, ACC: 54.93% \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r16it [01:27,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-14 18:11:08 [51] Lr: 0.000218, Training: 28.07%,  Loss: 2.40154, ACC: 54.50% \r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-xbj1ELnMFul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing"
      ],
      "metadata": {
        "id": "sRgD8Js-J82E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = ECAPAModel(lr, lr_decay, C , n_class, m, s, test_step)"
      ],
      "metadata": {
        "id": "4DDqNY3XMFpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a6d73d6-7b23-4661-c40d-fce1c6305154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/s3prl/s3prl/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: https://huggingface.co/s3prl/converted_ckpts/resolve/main/wavlm_large.pt\n",
            "Destination: /root/.cache/s3prl/download/f2d5200177fd6a33b278b7b76b454f25cd8ee866d55c122e69fccf6c7467d37d.wavlm_large.pt\n",
            "100%|██████████| 1.18G/1.18G [00:12<00:00, 104MB/s] \n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06-21 10:33:31 Model para number = 324061337.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model.load_parameters(\"/content/gdrive/MyDrive/KLTN/source/wavlm_large/component/model_0049.model\")"
      ],
      "metadata": {
        "id": "NyRR7J93MFnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model.eval_network(eval_list, eval_path)"
      ],
      "metadata": {
        "id": "d1hfU6PTFlCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03f9a9c6-57d3-4821-87e5-a3935a9b5d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/973 [00:00<?, ?it/s]<ipython-input-15-b61162519fae>:62: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  feats = numpy.stack(feats, axis = 0).astype(numpy.float)\n",
            "100%|██████████| 973/973 [10:35<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.85, 0.31090000000000007)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "-W0oWdc6K5Ip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# info"
      ],
      "metadata": {
        "id": "iyyqtbJkP58K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo -q\n",
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "rseCuaZQLf6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model.speaker_encoder, input_size=(1, 48000)) # component"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15f0FpKlE7kF",
        "outputId": "2f6d9737-0d5d-4912-abd8-eaba3d6d9978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                                            Output Shape              Param #\n",
              "===================================================================================================================\n",
              "ECAPA_TDNN                                                        [1, 256]                  25\n",
              "├─UpstreamExpert: 1-1                                             --                        --\n",
              "│    └─WavLM: 2-1                                                 --                        1,024\n",
              "│    │    └─ConvFeatureExtractionModel: 3-1                       [1, 512, 149]             (4,206,592)\n",
              "│    │    └─LayerNorm: 3-2                                        [1, 149, 512]             (1,024)\n",
              "│    │    └─Linear: 3-3                                           [1, 149, 1024]            (525,312)\n",
              "│    │    └─Dropout: 3-4                                          [1, 149, 1024]            --\n",
              "│    │    └─TransformerEncoder: 3-5                               [1, 149, 1024]            (310,719,168)\n",
              "├─InstanceNorm1d: 1-2                                             [1, 1024, 149]            --\n",
              "├─Conv1dReluBn: 1-3                                               [1, 512, 149]             --\n",
              "│    └─Conv1d: 2-2                                                [1, 512, 149]             (2,621,952)\n",
              "│    └─BatchNorm1d: 2-3                                           [1, 512, 149]             (1,024)\n",
              "├─SE_Res2Block: 1-4                                               [1, 512, 149]             --\n",
              "│    └─Conv1dReluBn: 2-4                                          [1, 512, 149]             --\n",
              "│    │    └─Conv1d: 3-6                                           [1, 512, 149]             (262,656)\n",
              "│    │    └─BatchNorm1d: 3-7                                      [1, 512, 149]             (1,024)\n",
              "│    └─Res2Conv1dReluBn: 2-5                                      [1, 512, 149]             --\n",
              "│    │    └─ModuleList: 3-20                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-21                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-20                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-21                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-20                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-21                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-20                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-21                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-20                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-21                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-20                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-21                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-20                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-21                                      --                        (recursive)\n",
              "│    └─Conv1dReluBn: 2-6                                          [1, 512, 149]             --\n",
              "│    │    └─Conv1d: 3-22                                          [1, 512, 149]             (262,656)\n",
              "│    │    └─BatchNorm1d: 3-23                                     [1, 512, 149]             (1,024)\n",
              "│    └─SE_Connect: 2-7                                            [1, 512, 149]             --\n",
              "│    │    └─Linear: 3-24                                          [1, 128]                  (65,664)\n",
              "│    │    └─Linear: 3-25                                          [1, 512]                  (66,048)\n",
              "├─SE_Res2Block: 1-5                                               [1, 512, 149]             --\n",
              "│    └─Conv1dReluBn: 2-8                                          [1, 512, 149]             --\n",
              "│    │    └─Conv1d: 3-26                                          [1, 512, 149]             (262,656)\n",
              "│    │    └─BatchNorm1d: 3-27                                     [1, 512, 149]             (1,024)\n",
              "│    └─Res2Conv1dReluBn: 2-9                                      [1, 512, 149]             --\n",
              "│    │    └─ModuleList: 3-40                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-41                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-40                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-41                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-40                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-41                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-40                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-41                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-40                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-41                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-40                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-41                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-40                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-41                                      --                        (recursive)\n",
              "│    └─Conv1dReluBn: 2-10                                         [1, 512, 149]             --\n",
              "│    │    └─Conv1d: 3-42                                          [1, 512, 149]             (262,656)\n",
              "│    │    └─BatchNorm1d: 3-43                                     [1, 512, 149]             (1,024)\n",
              "│    └─SE_Connect: 2-11                                           [1, 512, 149]             --\n",
              "│    │    └─Linear: 3-44                                          [1, 128]                  (65,664)\n",
              "│    │    └─Linear: 3-45                                          [1, 512]                  (66,048)\n",
              "├─SE_Res2Block: 1-6                                               [1, 512, 149]             --\n",
              "│    └─Conv1dReluBn: 2-12                                         [1, 512, 149]             --\n",
              "│    │    └─Conv1d: 3-46                                          [1, 512, 149]             (262,656)\n",
              "│    │    └─BatchNorm1d: 3-47                                     [1, 512, 149]             (1,024)\n",
              "│    └─Res2Conv1dReluBn: 2-13                                     [1, 512, 149]             --\n",
              "│    │    └─ModuleList: 3-60                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-61                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-60                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-61                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-60                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-61                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-60                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-61                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-60                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-61                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-60                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-61                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-60                                      --                        (recursive)\n",
              "│    │    └─ModuleList: 3-61                                      --                        (recursive)\n",
              "│    └─Conv1dReluBn: 2-14                                         [1, 512, 149]             --\n",
              "│    │    └─Conv1d: 3-62                                          [1, 512, 149]             (262,656)\n",
              "│    │    └─BatchNorm1d: 3-63                                     [1, 512, 149]             (1,024)\n",
              "│    └─SE_Connect: 2-15                                           [1, 512, 149]             --\n",
              "│    │    └─Linear: 3-64                                          [1, 128]                  (65,664)\n",
              "│    │    └─Linear: 3-65                                          [1, 512]                  (66,048)\n",
              "├─Conv1d: 1-7                                                     [1, 1536, 149]            (2,360,832)\n",
              "├─AttentiveStatsPool: 1-8                                         [1, 3072]                 --\n",
              "│    └─Conv1d: 2-16                                               [1, 128, 149]             (196,736)\n",
              "│    └─Conv1d: 2-17                                               [1, 1536, 149]            (198,144)\n",
              "├─BatchNorm1d: 1-9                                                [1, 3072]                 (6,144)\n",
              "├─Linear: 1-10                                                    [1, 256]                  (786,688)\n",
              "├─Sequential: 1-11                                                [1, 256]                  --\n",
              "│    └─Linear: 2-18                                               [1, 256]                  65,792\n",
              "│    └─Linear: 2-19                                               [1, 256]                  65,792\n",
              "│    └─Linear: 2-20                                               [1, 256]                  65,792\n",
              "===================================================================================================================\n",
              "Total params: 324,061,337\n",
              "Trainable params: 197,376\n",
              "Non-trainable params: 323,863,961\n",
              "Total mult-adds (G): 47.06\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.19\n",
              "Forward/backward pass size (MB): 387.46\n",
              "Params size (MB): 893.19\n",
              "Estimated Total Size (MB): 1280.84\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Z1sBKVNFnYtN"
      }
    }
  ]
}