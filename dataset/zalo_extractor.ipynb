{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fw32wZGl7GyA",
        "outputId": "92d8f6d6-8890-4cc6-d7e3-a6548e28807f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S8ixamCgTn5d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ObRqTSnlTqww"
      },
      "source": [
        "# Processing archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-BHbAIt7sMJ",
        "outputId": "8dce62db-78c4-4784-ad1d-71f6a01baf16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/MyDrive/KLTN/dataset/zalo_dataset/Train-Test-Data.zip\n",
            " extracting: dataset.zip             \n",
            "  inflating: public-test.csv         \n",
            " extracting: public-test.zip         \n",
            "  inflating: sample_submission.csv   \n"
          ]
        }
      ],
      "source": [
        "# !unzip /content/gdrive/MyDrive/KLTN/dataset/zalo_dataset/Train-Test-Data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe5lwZd3FKNG"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdncUQcOFkzm"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/public-test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zndi1-n_FhsX"
      },
      "outputs": [],
      "source": [
        "# !mv /content/dataset /content/gdrive/MyDrive/KLTN/dataset/zalo_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8SbvckkGDGH"
      },
      "outputs": [],
      "source": [
        "# !mv /content/public-test /content/gdrive/MyDrive/KLTN/dataset/zalo_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SwcO_rJGHcW"
      },
      "outputs": [],
      "source": [
        "# !mv /content/public-test.csv /content/gdrive/MyDrive/KLTN/dataset/zalo_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC0_OcQKnq42",
        "outputId": "147cd91c-825f-41f1-fccb-21e819d3c22a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/dataset/706-M-41/724-M-31\n",
            "/content/dataset/706-M-41/725-F-28\n",
            "/content/dataset/706-M-41/726-M-34\n",
            "/content/dataset/706-M-41/727-F-35\n",
            "/content/dataset/633-F-28/601-F-27\n",
            "/content/dataset/633-F-28/602-F-37\n",
            "/content/dataset/633-F-28/603-M-39\n",
            "/content/dataset/633-F-28/600-M-29\n"
          ]
        }
      ],
      "source": [
        "# for data in os.listdir(\"/content/dataset\"):\n",
        "#   for x in os.listdir(os.path.join(\"/content/dataset\", data)):\n",
        "#     if os.path.isdir(os.path.join(\"/content/dataset\",data,x)):\n",
        "#       print(os.path.join(\"/content/dataset\",data,x))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SRzu1oTS-HHX"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEu6EJXy-rEa"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tJLtRag9BEY"
      },
      "outputs": [],
      "source": [
        "const_path = '/content/gdrive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi0F5vo9C6Xl"
      },
      "outputs": [],
      "source": [
        "zalo_path = const_path + '/KLTN/dataset/zalo_dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-K2wS2Q_R8r"
      },
      "outputs": [],
      "source": [
        "train_path = zalo_path+ \"/dataset_fix/train\"\n",
        "test_path = zalo_path+ \"/dataset_fix/test\"\n",
        "val_path = zalo_path+ \"/dataset_fix/val\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gLiwAEnDThfE"
      },
      "source": [
        "# List generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxBACgXK-rBn"
      },
      "outputs": [],
      "source": [
        "def list_generator(list_path, wav_path, data_type):\n",
        "    with open(list_path +\"/\"+ data_type+\"_list.txt\",'w') as f:\n",
        "        for speaker_id in os.listdir(wav_path):\n",
        "          files = glob.glob(os.path.join(wav_path,speaker_id)+ '/**/*.wav', recursive=True)\n",
        "          for i in range(len(files)):\n",
        "            files[i] = files[i].replace(wav_path+'/', '')\n",
        "            f.writelines(str(speaker_id)+\" \"+files[i].replace(\"\\\\\",\"/\")+\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhNm6IQg6ABr"
      },
      "outputs": [],
      "source": [
        "# https://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/veri_test.txt\n",
        "def verification_list_generator_veri(list_path, data_type, same_speaker_count, diff_speaker_count):\n",
        "    with open(list_path + \"/veri_val.txt\", 'w') as f:\n",
        "        with open(list_path + \"/\" + data_type + \"_list.txt\") as y:\n",
        "            lines = y.readlines()\n",
        "        dirs = list(set([x.split()[1] for x in lines]))\n",
        "        same_speaker_pairs = []\n",
        "        diff_speaker_pairs = []\n",
        "        dict = {}\n",
        "        # Generate same speaker\n",
        "        while (len(same_speaker_pairs)<same_speaker_count):\n",
        "          a = random.sample(dirs,2)\n",
        "          x, y = (hash(a[0]), hash(a[1])) if a[0] < a[1] else (hash(a[1]), hash(a[0]))\n",
        "          hash_val = round((x + y) * (x + y + 1) / 2 + x)\n",
        "          if not (dict.get(hash_val)):\n",
        "              dict[hash_val] = True\n",
        "              if a[0].split(\"/\")[0] == a[1].split(\"/\")[0]:\n",
        "                same_speaker_pairs.append((1, a[0],a[1]))\n",
        "\n",
        "        # Generate different speaker\n",
        "        while (len(diff_speaker_pairs)<diff_speaker_count):\n",
        "          a = random.sample(dirs,2)\n",
        "          x, y = (hash(a[0]), hash(a[1])) if a[0] < a[1] else (hash(a[1]), hash(a[0]))\n",
        "          hash_val = round((x + y) * (x + y + 1) / 2 + x)\n",
        "          if not (dict.get(hash_val)):\n",
        "              dict[hash_val] = True\n",
        "              if a[0].split(\"/\")[0] != a[1].split(\"/\")[0]:\n",
        "                diff_speaker_pairs.append((0, a[0],a[1]))\n",
        "\n",
        "\n",
        "        pairs = same_speaker_pairs + diff_speaker_pairs\n",
        "        random.shuffle(pairs)\n",
        "\n",
        "        for i in range(len(pairs)):\n",
        "            f.writelines(str(pairs[i][0]) + \" \" + str(pairs[i][1]) + \" \" + str(pairs[i][2]) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHt7khahOyrT"
      },
      "outputs": [],
      "source": [
        "def verification_list_generator(list_path, data_type, same_speaker_count, diff_speaker_count):\n",
        "    with open(list_path + \"/verification_\" + data_type + \"_list.txt\", 'w') as f:\n",
        "        with open(list_path + \"/\" + data_type + \"_list.txt\") as y:\n",
        "            lines = y.readlines()\n",
        "        dirs = list(set([x.split()[1] for x in lines]))\n",
        "        same_speaker_pairs = []\n",
        "        diff_speaker_pairs = []\n",
        "        dict = {}\n",
        "        # Generate same speaker\n",
        "        while (len(same_speaker_pairs)<same_speaker_count):\n",
        "          a = random.sample(dirs,2)\n",
        "          x, y = (hash(a[0]), hash(a[1])) if a[0] < a[1] else (hash(a[1]), hash(a[0]))\n",
        "          hash_val = round((x + y) * (x + y + 1) / 2 + x)\n",
        "          if not (dict.get(hash_val)):\n",
        "              dict[hash_val] = True\n",
        "              if a[0].split(\"/\")[0] == a[1].split(\"/\")[0]:\n",
        "                same_speaker_pairs.append((a[0],a[1], 1))\n",
        "\n",
        "        # Generate different speaker\n",
        "        while (len(diff_speaker_pairs)<diff_speaker_count):\n",
        "          a = random.sample(dirs,2)\n",
        "          x, y = (hash(a[0]), hash(a[1])) if a[0] < a[1] else (hash(a[1]), hash(a[0]))\n",
        "          hash_val = round((x + y) * (x + y + 1) / 2 + x)\n",
        "          if not (dict.get(hash_val)):\n",
        "              dict[hash_val] = True\n",
        "              if a[0].split(\"/\")[0] != a[1].split(\"/\")[0]:\n",
        "                diff_speaker_pairs.append((a[0],a[1], 0))\n",
        "\n",
        "\n",
        "        pairs = same_speaker_pairs + diff_speaker_pairs\n",
        "        random.shuffle(pairs)\n",
        "\n",
        "        for i in tqdm(range(len(pairs))):\n",
        "            f.writelines(str(pairs[i][0]) + \" \" + str(pairs[i][1]) + \" \" + str(pairs[i][2]) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tnxReM7-q-a"
      },
      "outputs": [],
      "source": [
        "list_generator(zalo_path, train_path , \"train\")\n",
        "list_generator(zalo_path, test_path , \"test\")\n",
        "list_generator(zalo_path, val_path , \"val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQzVHPaUDz_L"
      },
      "outputs": [],
      "source": [
        "verification_list_generator_veri(zalo_path, \"val\", 10000, 10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u91cWC6s0tw7",
        "outputId": "63a4f813-b093-495e-bd83-686ddee9bce9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20000/20000 [00:00<00:00, 214110.35it/s]\n"
          ]
        }
      ],
      "source": [
        "verification_list_generator(zalo_path, \"test\", 10000, 10000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DTImD1zZMvh6"
      },
      "source": [
        "## Check duplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "posRuC8mIZNw",
        "outputId": "cfdde9fb-02c1-4092-8c73-8d5e4b0e2a51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20000/20000 [00:41<00:00, 482.52it/s] \n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/gdrive/MyDrive/KLTN/dataset/zalo_dataset/verification_test_list.txt\", 'r') as f:\n",
        "  lines = f.readlines()\n",
        "data = []\n",
        "for x in lines:\n",
        "  tmp = x.split()\n",
        "  pair = [tmp[0], tmp[1]]\n",
        "  pair.sort()\n",
        "  data.append(pair)\n",
        "for i in tqdm(range(len(data))):\n",
        "    for j in range(i+1, len(data)):\n",
        "        if data[i] == data[j]:\n",
        "            print(f\"Same found: {data[i]} vs {data[j]}\")\n",
        "            print(i, j)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
